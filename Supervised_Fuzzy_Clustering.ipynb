{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised_Fuzzy_Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCxHj0rjzb8D7AdKNbKhgH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaghayegh5ghasemi/supervised_fuzzy_clustering/blob/main/Supervised_Fuzzy_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J7dz3ovFH3t"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# load data\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=1, shuffle=True, num_workers=0)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# plot the image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy() # convert from tensor\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf288Mi7Xzqi",
        "outputId": "de04fa91-fbbc-41d0-9b0e-8d23404590d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import Image\n",
        "\n",
        "def make_window(img, label):\n",
        "  windows = img.unfold(1, 3, 2).unfold(2, 3, 2) # unflod(dimension, size, step)\n",
        "  selected_windows = []\n",
        "  for n in range(2):\n",
        "    i = torch.randint(0, 14, (1, 1))\n",
        "    j = torch.randint(0, 14, (1, 1))\n",
        "    temp = windows[:, i[0, 0], j[0, 0]].reshape((27, 1))\n",
        "    selected_windows.append([temp, label])\n",
        "  return selected_windows\n",
        "\n",
        "def make_dataset():\n",
        "  dataset = []\n",
        "  for i, (inputs, labels) in enumerate(trainloader):\n",
        "    if i == 1000:\n",
        "      break\n",
        "    dataset = dataset + make_window(inputs[0], labels[0])\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "m0jhR6h4Zdwu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = make_dataset()"
      ],
      "metadata": {
        "id": "nR3Bnq9ZbiUF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the centroids and the parameters\n",
        "gamma = 1\n",
        "sigma = 0.7\n",
        "threshold = 0.0004\n",
        "beta = 1\n",
        "\n",
        "number_of_dimensions = 27\n",
        "centroids = []\n",
        "covariances = []\n",
        "inverted_covariances = []"
      ],
      "metadata": {
        "id": "kCV7HeM6WZYJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mahanalobis_distance(icm, m, x):\n",
        "  # D^2 = (x-m)^T * C^-1 * (x-m), mahanalobis distance formula\n",
        "  s = x-m\n",
        "  return float(s.T@icm@s)"
      ],
      "metadata": {
        "id": "dzj-L1pZSUFS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_centroids(dataset, number_of_dimensions, centroids, inverted_covariances, covariances, gamma, sigma, threshold):\n",
        "  number_of_centroids = len(centroids)\n",
        "  for data in dataset:\n",
        "    if number_of_centroids == 0:\n",
        "      number_of_centroids += 1\n",
        "      centroids.append(data)\n",
        "      covariances.append(sigma*torch.eye(number_of_dimensions))\n",
        "      inverted_covariances.append(torch.eye(number_of_dimensions)/sigma)\n",
        "    else:\n",
        "      distances = []\n",
        "      for i in range(number_of_centroids):\n",
        "        centroid = centroids[i]\n",
        "        icm = inverted_covariances[i]\n",
        "        distances.append(calculate_mahanalobis_distance(icm, centroid[0], data[0]))\n",
        "      distances = -1*gamma*np.array(distances)\n",
        "      RM = np.exp(distances)\n",
        "      if max(RM) < threshold:\n",
        "        number_of_centroids += 1\n",
        "        centroids.append(data)\n",
        "        covariances.append(sigma*torch.eye(number_of_dimensions))\n",
        "        inverted_covariances.append(torch.eye(number_of_dimensions)/sigma)\n",
        "\n",
        "\n",
        "initialize_centroids(dataset, number_of_dimensions, centroids, inverted_covariances, covariances, gamma, sigma, threshold)\n"
      ],
      "metadata": {
        "id": "K4EAW-dkLCTh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_membership(icm, vi, x, gamma):\n",
        "  distance = calculate_mahanalobis_distance(icm, vi, x)\n",
        "  return np.exp(-1*gamma*distance)"
      ],
      "metadata": {
        "id": "guCsuBWzd533"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_q_ij(centroids, inverted_covariances, classes, dataset, gamma):\n",
        "  q = np.zeros((len(centroids), len(classes))) # i = number of clusters, j = number of classes\n",
        "  for i in range(len(centroids)):\n",
        "    centroid = centroids[i][0]\n",
        "    icm = inverted_covariances[i]\n",
        "    for j in range(len(classes)):\n",
        "      numinator = 0\n",
        "      denuminator = 0\n",
        "      for data in dataset:\n",
        "        vector = data[0]\n",
        "        label = data[1]\n",
        "        miu_ik = calculate_membership(icm, centroid, vector, gamma)\n",
        "        if int(label) == j:\n",
        "          numinator += miu_ik\n",
        "        denuminator += miu_ik\n",
        "      q[i][j] = numinator/denuminator\n",
        "  return q"
      ],
      "metadata": {
        "id": "jEQwR5mhgDKE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = calculate_q_ij(centroids, inverted_covariances, classes, dataset, gamma)\n",
        "print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoJdBWaY2vDa",
        "outputId": "cae12563-0140-4760-a1f4-3b2b8aef8b7b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.32064368e-003 5.48408663e-001 1.22721407e-001 4.41460084e-002\n",
            "  2.18306251e-002 2.91480475e-002 4.66350592e-003 1.15764757e-001\n",
            "  1.01309125e-001 8.68721765e-003]\n",
            " [2.18776492e-002 3.63950790e-001 1.67949072e-001 4.26770802e-002\n",
            "  2.29302422e-003 2.30932574e-001 1.10662295e-002 2.88188327e-003\n",
            "  3.18147151e-002 1.24556982e-001]\n",
            " [2.37462467e-001 3.87438995e-002 1.06964947e-001 5.01836011e-002\n",
            "  1.69393333e-004 4.82272245e-001 1.72102228e-020 1.10418828e-002\n",
            "  4.27110404e-002 3.04505246e-002]\n",
            " [6.81927800e-001 1.59991344e-003 1.84452018e-001 3.05826084e-003\n",
            "  1.36868716e-002 2.49796495e-002 5.58633956e-002 9.92199938e-003\n",
            "  2.15616886e-002 2.94840337e-003]\n",
            " [6.03788307e-002 1.68447438e-005 3.09432927e-002 6.85001642e-001\n",
            "  1.34614396e-002 2.51450277e-002 7.95445314e-003 1.98908273e-003\n",
            "  1.70805397e-001 4.30398977e-003]\n",
            " [8.45442855e-002 9.96145879e-009 6.72418352e-001 3.48225298e-003\n",
            "  1.81905351e-005 2.87689089e-003 1.04396543e-007 2.61517988e-004\n",
            "  2.31032775e-001 5.36562077e-003]\n",
            " [0.00000000e+000 0.00000000e+000 0.00000000e+000 1.00000000e+000\n",
            "  0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
            "  0.00000000e+000 0.00000000e+000]\n",
            " [9.76979112e-041 8.84770381e-050 3.17751849e-046 1.45842964e-077\n",
            "  9.04883429e-069 5.19045640e-087 9.71826115e-126 1.50897152e-094\n",
            "  1.00000000e+000 9.06530544e-056]\n",
            " [9.58163853e-001 8.22995490e-006 4.72575663e-004 1.69897359e-005\n",
            "  4.93632356e-012 3.18038888e-007 3.76910632e-013 1.21797634e-006\n",
            "  4.13366945e-002 1.21273987e-007]\n",
            " [3.06435056e-001 5.00610864e-004 9.65240362e-002 2.98130404e-003\n",
            "  1.29805822e-002 5.33326395e-001 2.82791662e-002 2.46122762e-003\n",
            "  9.86951802e-003 6.64210428e-003]\n",
            " [2.43435089e-005 1.38027543e-003 1.49427151e-004 1.46145461e-005\n",
            "  9.96962933e-001 5.95007074e-004 4.16271937e-007 2.43023931e-007\n",
            "  1.50270582e-004 7.22469414e-004]\n",
            " [1.42243809e-002 9.43263637e-003 7.80252306e-002 6.37163431e-001\n",
            "  5.21544022e-002 1.54940609e-001 4.27591995e-002 2.27234335e-003\n",
            "  7.13065362e-003 1.89711397e-003]\n",
            " [1.67994764e-002 3.13901166e-006 3.86556241e-002 1.49084523e-004\n",
            "  3.88417147e-004 9.38825601e-001 4.73191673e-003 1.10776647e-005\n",
            "  9.50128650e-006 4.26161827e-004]\n",
            " [8.09944214e-003 1.05626140e-003 1.34515239e-001 2.47830910e-002\n",
            "  7.88110678e-001 3.21472798e-002 5.37694148e-003 1.23574679e-003\n",
            "  9.11021099e-004 3.76429920e-003]\n",
            " [8.52563825e-001 2.49069543e-004 6.96080830e-002 6.31142987e-003\n",
            "  9.22908000e-003 3.49423269e-002 9.56730368e-003 4.66998371e-003\n",
            "  1.22440163e-002 6.14882434e-004]\n",
            " [1.41905980e-001 6.48120314e-001 1.04529789e-002 1.36922848e-004\n",
            "  6.08059535e-004 2.49619481e-002 4.26191108e-005 5.51874960e-003\n",
            "  1.64870733e-001 3.38169432e-003]\n",
            " [4.61244031e-006 2.16061401e-064 3.27055354e-055 2.05821474e-064\n",
            "  3.41284681e-092 7.16233508e-069 4.63628907e-044 1.78024306e-066\n",
            "  3.24979243e-009 9.99995384e-001]\n",
            " [2.96918029e-026 9.99999998e-001 7.60142219e-014 4.82320564e-014\n",
            "  3.37757105e-011 1.87332702e-009 5.61877641e-019 1.13438069e-011\n",
            "  6.93011366e-023 1.61656775e-017]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
            "  0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
            "  0.00000000e+000 0.00000000e+000]\n",
            " [7.82570901e-072 1.06868719e-307 3.14007221e-237 0.00000000e+000\n",
            "  1.00808898e-281 3.66312380e-117 9.02172608e-001 6.00962303e-025\n",
            "  9.78273916e-002 2.33190657e-042]\n",
            " [5.78562739e-052 1.89512469e-203 3.25499968e-198 2.10727925e-007\n",
            "  0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
            "  3.66598027e-274 9.99999789e-001]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
            "  0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
            "  0.00000000e+000 6.68754884e-169]\n",
            " [1.85798766e-003 6.38141007e-001 2.55030599e-001 1.37291195e-003\n",
            "  4.77572450e-002 4.40546455e-002 9.17516965e-004 1.02517717e-003\n",
            "  8.53349494e-004 8.98955985e-003]\n",
            " [2.94193824e-001 1.00961061e-003 1.16148825e-001 2.87874784e-003\n",
            "  6.99977870e-003 4.81025041e-001 8.46697854e-002 2.64154169e-003\n",
            "  9.83395494e-003 5.98891172e-004]\n",
            " [0.00000000e+000 0.00000000e+000 0.00000000e+000 2.17666432e-293\n",
            "  0.00000000e+000 8.41581707e-245 0.00000000e+000 0.00000000e+000\n",
            "  0.00000000e+000 1.00000000e+000]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
            "  0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
            "  0.00000000e+000 0.00000000e+000]\n",
            " [1.27777231e-148 5.30359569e-209 0.00000000e+000 0.00000000e+000\n",
            "  3.17745266e-207 4.51935314e-316 0.00000000e+000 1.00000000e+000\n",
            "  1.22634566e-026 0.00000000e+000]\n",
            " [1.21043924e-149 1.00000000e+000 3.90513442e-107 1.68664212e-112\n",
            "  3.76588401e-192 2.40146697e-142 1.35581539e-249 3.22701016e-162\n",
            "  1.20482156e-152 1.86854143e-214]\n",
            " [2.18933380e-001 4.21301650e-004 1.15082626e-001 1.01742177e-003\n",
            "  6.05413205e-003 5.54081459e-001 7.14148085e-002 3.47605946e-003\n",
            "  6.08494119e-003 2.34338710e-002]\n",
            " [            nan             nan             nan             nan\n",
            "              nan             nan             nan             nan\n",
            "              nan             nan]\n",
            " [2.34272488e-005 9.99550438e-001 4.06023118e-007 1.38047878e-007\n",
            "  1.09665433e-005 3.68018748e-006 1.00993045e-013 2.53468171e-020\n",
            "  4.38894451e-008 4.10899825e-004]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_centroids(centroids, inverted_covariances, classes, dataset, gamma, beta):\n",
        "  q = calculate_q_ij(centroids, inverted_covariances, classes, dataset, gamma)\n",
        "  for i in range(len(centroids)):\n",
        "    centroid = centroids[i][0]\n",
        "    icm = inverted_covariances[i]\n",
        "    numinator = torch.zeros((27, 1))\n",
        "    denuminator = 0\n",
        "    for data in dataset:\n",
        "      vector = data[0]\n",
        "      label = data[1]\n",
        "      miu_ik = calculate_membership(icm, centroid, vector, gamma)\n",
        "      p_ik = q[i][int(label)]\n",
        "      numinator += (miu_ik*p_ik)*vector\n",
        "      denuminator += miu_ik*p_ik\n",
        "    centroids[i][0] = (1-beta)*centroid + (beta/denuminator)*(numinator)"
      ],
      "metadata": {
        "id": "OjKYJzLddKZd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_inverted_covariance(covariance):\n",
        "  covariance = np.array(covariance)\n",
        "  l, mygamma = np.linalg.eig(covariance) # calculate eigenvalues and eigenvectors\n",
        "  mylambda = np.diag(1/l) # construct a diagnosal matrix with eigenvalues\n",
        "  icm = (mygamma)@(mylambda)@(mygamma.T) # invert of the covariance matrix\n",
        "  return torch.tensor(icm)"
      ],
      "metadata": {
        "id": "1j8qU4JJvori"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_covariances(centroids, covariances, inverted_covariances, classes, dataset, gamma, beta):\n",
        "  q = calculate_q_ij(centroids, inverted_covariances, classes, dataset, gamma)\n",
        "  for i in range(len(centroids)):\n",
        "    centroid = centroids[i][0]\n",
        "    icm = inverted_covariances[i]\n",
        "    numinator = torch.zeros((27, 27))\n",
        "    denuminator = 0\n",
        "    for data in dataset:\n",
        "      vector = data[0]\n",
        "      label = data[1]\n",
        "      miu_ik = calculate_membership(icm, centroid, vector, gamma)\n",
        "      p_ik = q[i][int(label)]\n",
        "      numinator += (miu_ik*p_ik)*((vector-centroid)@(vector-centroid).T)\n",
        "      denuminator += miu_ik*p_ik\n",
        "    covariances[i] = (1-beta)*covariances[i] + (beta/denuminator)*(numinator)\n",
        "    inverted_covariances[i] = calculate_inverted_covariance(covariances[i])"
      ],
      "metadata": {
        "id": "knbnwv89pU6v"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def calculate_entropy(centroids, inverted_covariances, classes, dataset, gamma):\n",
        "  q = calculate_q_ij(centroids, inverted_covariances, classes, dataset, gamma)\n",
        "  ent = 0\n",
        "  for i in range(len(centroids)):\n",
        "    for data in dataset:\n",
        "      vector = data[0]\n",
        "      label = data[1]\n",
        "      p_ik = q[i][int(label)]\n",
        "      ent += -1*p_ik*math.log2(p_ik)\n",
        "  return ent"
      ],
      "metadata": {
        "id": "apVhQznhzTHj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  update_centroids(centroids, inverted_covariances, classes, dataset, gamma, beta)\n",
        "  update_covariances(centroids, covariances, inverted_covariances, classes, dataset, gamma, beta)\n",
        "  print(calculate_entropy(centroids, inverted_covariances, classes, dataset, gamma))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "Hj_3eev80P9W",
        "outputId": "982597b1-471e-431a-d764-8116dee6a5cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-927851c9d10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mupdate_centroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverted_covariances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mupdate_covariances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverted_covariances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverted_covariances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-dad65c0fdd0f>\u001b[0m in \u001b[0;36mcalculate_entropy\u001b[0;34m(centroids, inverted_covariances, classes, dataset, gamma)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mp_ik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0ment\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mp_ik\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_ik\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: math domain error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(100): \n",
        "#     if labels[i] == 9: \n",
        "#       print(images[i])\n",
        "#       #imshow(torchvision.utils.make_grid(images[i]))\n",
        "#       print(' '.join('%5s' % classes[labels[i]]))\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images[0]))\n",
        "lists = make_window(img, labels[55])\n",
        "# print(labels[55])\n",
        "# imshow(torchvision.utils.make_grid(lists[55][0]))\n",
        "#print(lists[55][1])\n",
        "# print(lists[55][0])\n",
        "# print(len(lists[55][0]))\n",
        "\n",
        "for i in range(len(lists)): \n",
        "  imshow(torchvision.utils.make_grid(lists[i][0]))\n",
        "  print(' '.join('%5s' % classes[lists[i][1]]))\n",
        "\n",
        "\n",
        "imshow(torchvision.utils.make_grid(dataset[120][0]))\n",
        "print(' '.join('%5s' % classes[dataset[120][1]]))\n",
        "\n",
        "# get some random training images\n",
        "# dataiter = iter(trainloader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# patches = make_window(images[0], labels[0])\n",
        "\n",
        "# for i in range(len(patches)):\n",
        "#   print(patches[i][0].shape)"
      ],
      "metadata": {
        "id": "M-OcUBtXYDqT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}