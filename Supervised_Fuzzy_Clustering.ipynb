{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised_Fuzzy_Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7KlmyePVyUx6GHjc8C1uj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaghayegh5ghasemi/supervised_fuzzy_clustering/blob/main/Supervised_Fuzzy_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J7dz3ovFH3t"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# load data\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=1, shuffle=True, num_workers=0)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# plot the image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy() # convert from tensor\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf288Mi7Xzqi",
        "outputId": "57243182-3987-4cfd-ecad-56b64976d144"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import Image\n",
        "\n",
        "def make_window(img, label):\n",
        "  windows = img.unfold(1, 3, 2).unfold(2, 3, 2) # unflod(dimension, size, step)\n",
        "  selected_windows = []\n",
        "  for n in range(2):\n",
        "    i = torch.randint(0, 14, (1, 1))\n",
        "    j = torch.randint(0, 14, (1, 1))\n",
        "    temp = windows[:, i[0, 0], j[0, 0]].reshape((27, 1))\n",
        "    selected_windows.append([temp, label])\n",
        "  return selected_windows\n",
        "\n",
        "def make_dataset():\n",
        "  dataset = []\n",
        "  for i, (inputs, labels) in enumerate(trainloader):\n",
        "    if i == 1000:\n",
        "      break\n",
        "    dataset = dataset + make_window(inputs[0], labels[0])\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "m0jhR6h4Zdwu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = make_dataset()"
      ],
      "metadata": {
        "id": "nR3Bnq9ZbiUF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the centroids and the parameters\n",
        "gamma = 1\n",
        "sigma = 0.7\n",
        "threshold = 0.0004\n",
        "beta = 1\n",
        "\n",
        "number_of_dimensions = 27\n",
        "centroids = []\n",
        "covariances = []\n",
        "inverted_covariances = []"
      ],
      "metadata": {
        "id": "kCV7HeM6WZYJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mahanalobis_distance(icm, m, x):\n",
        "  # D^2 = (x-m)^T * C^-1 * (x-m), mahanalobis distance formula\n",
        "  s = x-m\n",
        "  return float(s.T@icm@s)"
      ],
      "metadata": {
        "id": "dzj-L1pZSUFS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_centroids(dataset, number_of_dimensions, centroids, inverted_covariances, covariances, gamma, sigma, threshold):\n",
        "  number_of_centroids = len(centroids)\n",
        "  for data in dataset:\n",
        "    if number_of_centroids == 0:\n",
        "      number_of_centroids += 1\n",
        "      centroids.append(data)\n",
        "      covariances.append(sigma*torch.eye(number_of_dimensions))\n",
        "      inverted_covariances.append(torch.eye(number_of_dimensions)/sigma)\n",
        "    else:\n",
        "      distances = []\n",
        "      for i in range(number_of_centroids):\n",
        "        centroid = centroids[i]\n",
        "        icm = inverted_covariances[i]\n",
        "        distances.append(calculate_mahanalobis_distance(icm, centroid[0], data[0]))\n",
        "      distances = -1*gamma*np.array(distances)\n",
        "      RM = np.exp(distances)\n",
        "      if max(RM) < threshold:\n",
        "        number_of_centroids += 1\n",
        "        centroids.append(data)\n",
        "        covariances.append(sigma*torch.eye(number_of_dimensions))\n",
        "        inverted_covariances.append(torch.eye(number_of_dimensions)/sigma)\n",
        "\n",
        "\n",
        "initialize_centroids(dataset, number_of_dimensions, centroids, inverted_covariances, covariances, gamma, sigma, threshold)\n"
      ],
      "metadata": {
        "id": "K4EAW-dkLCTh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_membership(icm, vi, x, gamma):\n",
        "  distance = calculate_mahanalobis_distance(icm, vi, x)\n",
        "  return np.exp(-1*gamma*distance)"
      ],
      "metadata": {
        "id": "guCsuBWzd533"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_q_ij(centroids, inverted_covariances, classes, dataset, gamma):\n",
        "  q = np.zeros((len(centroids), len(classes))) # i = number of clusters, j = number of classes\n",
        "  for i in range(len(centroids)):\n",
        "    centroid = centroids[i][0]\n",
        "    icm = inverted_covariances[i]\n",
        "    for j in range(len(classes)):\n",
        "      numinator = 0\n",
        "      denuminator = 0\n",
        "      for data in dataset:\n",
        "        vector = data[0]\n",
        "        label = data[1]\n",
        "        miu_ik = calculate_membership(icm, centroid, vector, gamma)\n",
        "        if int(label) == j:\n",
        "          numinator += miu_ik\n",
        "        denuminator += miu_ik\n",
        "      q[i][j] = numinator/denuminator\n",
        "  return q"
      ],
      "metadata": {
        "id": "jEQwR5mhgDKE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_centroids(centroids, inverted_covariances, classes, dataset, gamma, beta):\n",
        "  q = calculate_q_ij(centroids, inverted_covariances, classes, dataset, gamma)\n",
        "  for i in range(len(centroids)):\n",
        "    centroid = centroids[i][0]\n",
        "    icm = inverted_covariances[i]\n",
        "    numinator = torch.zeros((27, 1))\n",
        "    denuminator = 0\n",
        "    for data in dataset:\n",
        "      vector = data[0]\n",
        "      label = data[1]\n",
        "      miu_ik = calculate_membership(icm, centroid, vector, gamma)\n",
        "      p_ik = q[i][int(label)]\n",
        "      numinator += (miu_ik*p_ik)*vector\n",
        "      denuminator += miu_ik*p_ik\n",
        "    centroids[i][0] = (1-beta)*centroid + (beta/denuminator)*(numinator)"
      ],
      "metadata": {
        "id": "OjKYJzLddKZd"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(centroids[0])\n",
        "update_centroids(centroids, inverted_covariances, classes, dataset, gamma, beta)\n",
        "print(\"**************************\")\n",
        "print(centroids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k73Ra_Smdig",
        "outputId": "8c5cef7b-d983-4a3b-c160-597b3e98cd0b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 0.0183],\n",
            "        [ 0.0122],\n",
            "        [ 0.0113],\n",
            "        [ 0.0113],\n",
            "        [ 0.0060],\n",
            "        [ 0.0099],\n",
            "        [ 0.0123],\n",
            "        [ 0.0041],\n",
            "        [ 0.0050],\n",
            "        [ 0.0251],\n",
            "        [ 0.0182],\n",
            "        [ 0.0155],\n",
            "        [ 0.0199],\n",
            "        [ 0.0135],\n",
            "        [ 0.0155],\n",
            "        [ 0.0206],\n",
            "        [ 0.0117],\n",
            "        [ 0.0123],\n",
            "        [-0.0304],\n",
            "        [-0.0391],\n",
            "        [-0.0400],\n",
            "        [-0.0341],\n",
            "        [-0.0422],\n",
            "        [-0.0404],\n",
            "        [-0.0357],\n",
            "        [-0.0430],\n",
            "        [-0.0439]]), tensor(6)]\n",
            "**************************\n",
            "[tensor([[ 0.0308],\n",
            "        [ 0.0242],\n",
            "        [ 0.0236],\n",
            "        [ 0.0232],\n",
            "        [ 0.0179],\n",
            "        [ 0.0221],\n",
            "        [ 0.0243],\n",
            "        [ 0.0150],\n",
            "        [ 0.0157],\n",
            "        [ 0.0288],\n",
            "        [ 0.0208],\n",
            "        [ 0.0179],\n",
            "        [ 0.0222],\n",
            "        [ 0.0153],\n",
            "        [ 0.0175],\n",
            "        [ 0.0228],\n",
            "        [ 0.0125],\n",
            "        [ 0.0130],\n",
            "        [-0.0588],\n",
            "        [-0.0689],\n",
            "        [-0.0695],\n",
            "        [-0.0637],\n",
            "        [-0.0728],\n",
            "        [-0.0711],\n",
            "        [-0.0648],\n",
            "        [-0.0737],\n",
            "        [-0.0751]]), tensor(6)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(100): \n",
        "#     if labels[i] == 9: \n",
        "#       print(images[i])\n",
        "#       #imshow(torchvision.utils.make_grid(images[i]))\n",
        "#       print(' '.join('%5s' % classes[labels[i]]))\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images[0]))\n",
        "lists = make_window(img, labels[55])\n",
        "# print(labels[55])\n",
        "# imshow(torchvision.utils.make_grid(lists[55][0]))\n",
        "#print(lists[55][1])\n",
        "# print(lists[55][0])\n",
        "# print(len(lists[55][0]))\n",
        "\n",
        "for i in range(len(lists)): \n",
        "  imshow(torchvision.utils.make_grid(lists[i][0]))\n",
        "  print(' '.join('%5s' % classes[lists[i][1]]))\n",
        "\n",
        "\n",
        "imshow(torchvision.utils.make_grid(dataset[120][0]))\n",
        "print(' '.join('%5s' % classes[dataset[120][1]]))\n",
        "\n",
        "# get some random training images\n",
        "# dataiter = iter(trainloader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# patches = make_window(images[0], labels[0])\n",
        "\n",
        "# for i in range(len(patches)):\n",
        "#   print(patches[i][0].shape)"
      ],
      "metadata": {
        "id": "M-OcUBtXYDqT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}